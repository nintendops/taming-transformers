model:
  base_learning_rate: 4.5e-06
  target: taming.models.refinement_ae.RefinementAE
  params:
    # ckpt_path: logs/2023-02-18T22-14-21_maskgit_refinement_pw01/checkpoints/last.ckpt
    embed_dim: 512
    n_embed: 1024
    image_key: "image"
    first_stage_config:
      target: taming.models.maskgit.MaskGIT
      params:
        ckpt_path: /data/Haiwei/taming_ckpts/2023-02-11T15-59-56_maskGIT_boxmask/checkpoints/last.ckpt
        cond_stage_key: segmentation
        sampling_ratio: 0.1
        transformer_config:
          target: taming.modules.transformer.mingpt.GPT
          params:
            vocab_size: 1025
            block_size: 512  # = 256 + 256 = dim(vqgan_latent_space,16x16) 
            n_layer: 24 # 24,40
            n_head: 16
            n_embd: 1408
            embd_pdrop: 0.1
            resid_pdrop: 0.1
            attn_pdrop: 0.1
        first_stage_config:
          target: taming.models.vqgan.VQModel
          params:
            ckpt_path: /data/Haiwei/taming_ckpts/2022-12-02T11-02-19_allusc_vqgan_1024_baseline_cont/checkpoints/last.ckpt
            embed_dim: 512
            n_embed: 1024
            ddconfig:
              padding_free: false
              double_z: false
              z_channels: 512
              resolution: 256
              in_channels: 3
              out_ch: 3
              ch: 128
              ch_mult:
              - 1
              - 1
              - 2
              - 2
              - 4
              num_res_blocks: 2
              attn_resolutions:
              - 16
              dropout: 0.0
            lossconfig:
              target: taming.modules.losses.DummyLoss
        cond_stage_config: "__is_unconditional__"
    ddconfig:
      padding_free: false
      double_z: false
      z_channels: 512
      resolution: 256
      in_channels: 4
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 1
      - 2
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions:
      - 16
      dropout: 0.0
    lossconfig:
      target: taming.modules.losses.vqperceptual.PIPSWithDiscriminator
      params:
        pixelloss_weight: 0.0
        perceptual_weight: 0.1
        r1_weight: 0.0
        perceptual_filter:
        - 3
        - 4
        disc_conditional: False
        disc_in_channels: 4
        disc_start: 0
        disc_weight: 1.0

# data:
#   target: main.DataModuleFromConfig
#   params:
#     batch_size: 8
#     train:
#       target: taming.data.owt.OWTBase
#       params:
#         size: 272
#         dataroot: "/home/ICT2000/chenh/Haiwei/Datasets/OWT/USC_Galen_Center"
#         crop_size: 256
data:
  target: main.DataModuleFromConfig
  params:
    batch_size: 8
    train:
      target: taming.data.owt.OWTMulti
      params:
        size: 272
        dataroot: "/data/Haiwei/Datasets/owt.txt"
        multiplier: 1
        crop_size: 256
    test:
      target: taming.data.owt.OWTBase
      params:
        size: 272
        dataroot: "/data/Haiwei/Datasets/USC/validate" # SourceImages
        multiplier: 1
        crop_size: 256
        ignore_segmentation: true
        split: "test"
